{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单的自编码器，用于自己摸索练习卷积和反卷积的\n",
    "心得就是，loss效果不好的时候，多想想网络哪里出了问题\n",
    "但是这里有小小的问题是z_dim层为2的时候，cycle的图像十分模糊。\n",
    "非线性的激活层对于卷积来说还是需要的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:04:19.962224Z",
     "start_time": "2018-12-18T11:04:16.012283Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import gridspec\n",
    "from tensorflow import keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:04:19.996377Z",
     "start_time": "2018-12-18T11:04:19.963940Z"
    }
   },
   "outputs": [],
   "source": [
    "z_dim = 128\n",
    "batch_size = 64\n",
    "image_w = 28\n",
    "image_h = 28\n",
    "image_d = 1\n",
    "input_dim = 784\n",
    "n_epochs = 40\n",
    "learning_rate = 0.001\n",
    "beta1 = 0.9\n",
    "\n",
    "class AE:\n",
    "    def __init__(self):\n",
    "        print(\"初始化自编码器\")\n",
    "        self.encoder_model = self.encoder()\n",
    "        self.encoder_model.summary()\n",
    "        self.decoder_model = self.decoder()\n",
    "        self.decoder_model.summary()\n",
    "\n",
    "    def cycle(self, x_input):\n",
    "        x_input = tf.reshape(x_input,shape=[-1,image_w,image_h,image_d])\n",
    "        latent_code = self.encoder_model(x_input)\n",
    "        self.latent_code = latent_code\n",
    "        x_output = self.decoder_model(latent_code)\n",
    "        x_output = tf.reshape(x_output,shape=[-1,image_w,image_h])\n",
    "        return x_output\n",
    "\n",
    "    def predict(self, decoder_input):\n",
    "        x_output = self.decoder_model(decoder_input)\n",
    "        return x_output\n",
    "\n",
    "    def encoder(self):\n",
    "        with tf.name_scope(\"encoder\"):\n",
    "            input = keras.layers.Input([image_h,image_w,image_d])\n",
    "            # x = keras.layers.Conv2D(z_dim//16, kernel_size=(5,5), strides=(2,2), padding='SAME')(input)\n",
    "            x = keras.layers.Conv2D(16, kernel_size=(2,2), strides=(2,2), padding='SAME')(input) #(14,14)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.LeakyReLU(0.2)(x)\n",
    "            x = keras.layers.Conv2D(32, kernel_size=(2,2), strides=(2,2), padding='SAME')(x) #(7,7)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.LeakyReLU(0.2)(x)\n",
    "            x = keras.layers.Conv2D(64, kernel_size=(2,2), strides=(2,2), padding='SAME')(x) # (4,4)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.LeakyReLU(0.2)(x)\n",
    "            x = keras.layers.Conv2D(z_dim, kernel_size=(2,2), strides=(2,2), padding='SAME')(x) # (2 2 2)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.LeakyReLU(0.2)(x)\n",
    "            output = keras.layers.GlobalAveragePooling2D()(x) # (2)\n",
    "            return keras.models.Model(input, output)\n",
    "\n",
    "    def decoder(self):\n",
    "        with tf.name_scope(\"decoder\"):\n",
    "            input = keras.layers.Input([z_dim])\n",
    "            x = keras.layers.Dense(2*2*z_dim)(input) # 为了化成和(2 2 z_dim)一样的大小，相当于逆GlobalAveragePooling2D\n",
    "            x = keras.layers.Reshape([2,2,z_dim])(x)\n",
    "            x = keras.layers.Conv2DTranspose(64, kernel_size=(2,2), strides=(2,2), padding='SAME')(x)#(4,4)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.Conv2DTranspose(32, kernel_size=(2,2), strides=(2,2), padding='SAME')(x)#(8,8)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.Conv2DTranspose(8, kernel_size=(2,2), strides=(3,3), padding='SAME')(x)#(24,24)\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "            x = keras.layers.Activation(\"relu\")(x)\n",
    "            x = keras.layers.Conv2DTranspose(image_d, kernel_size=(5,5), strides=(1,1), padding='VALID')(x)#(28*28*1)\n",
    "            output = keras.layers.Activation(\"relu\")(x)\n",
    "            return keras.models.Model(input, output)\n",
    "\n",
    "class dataset:\n",
    "    def __init__(self, data):\n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(\n",
    "            (data)).repeat().batch(batch_size)\n",
    "        self.iterator = self.dataset.make_initializable_iterator()\n",
    "        self.next_element = self.iterator.get_next()\n",
    "\n",
    "\n",
    "x_input = tf.placeholder(dtype=tf.float32, shape=[\n",
    "    batch_size, image_w, image_h], name='Input')\n",
    "x_target = tf.placeholder(dtype=tf.float32, shape=[\n",
    "    batch_size, image_w, image_h], name='Target')\n",
    "decoder_input = tf.placeholder(dtype=tf.float32, shape=[\n",
    "    1, z_dim], name='Decoder_input')\n",
    "\n",
    "\n",
    "def train(train_model):\n",
    "    (train_images, train_labels), (test_images,test_labels) = keras.datasets.mnist.load_data()\n",
    "    train_images = train_images/1\n",
    "    test_images = test_images/1\n",
    "    train_images_dataset = dataset(train_images)\n",
    "\n",
    "    autoencoder = AE()\n",
    "    x_output = autoencoder.cycle(x_input)\n",
    "    # decoder_output = autoencoder.predict(decoder_input)\n",
    "\n",
    "    input_images = tf.reshape(x_input, [-1, image_h, image_w, 1])\n",
    "    generated_images = tf.reshape(x_output, [-1, image_h, image_w, 1])\n",
    "    tf.summary.image(name='Input Images', tensor=input_images, max_outputs=10)\n",
    "    tf.summary.image(name='Generated Images',tensor=generated_images, max_outputs=10)\n",
    "\n",
    "    cycle_loss = tf.reduce_mean(tf.square(x_target - x_output))\n",
    "    tf.summary.scalar(\"loss\", cycle_loss)\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cycle_loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    global_step = 0\n",
    "    # Saving the model\n",
    "    saver = tf.train.Saver()\n",
    "    results_path = './Results/Autoencoder/'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for v in tf.trainable_variables():\n",
    "            print(v)\n",
    "        print(autoencoder.decoder_model.variables)\n",
    "        if train_model:\n",
    "            sess.run(train_images_dataset.iterator.initializer)\n",
    "            logdir = results_path + \\\n",
    "                time.strftime(\"%Y-%m-%d %Hh%Mm%Ss\", time.localtime())\n",
    "            print(logdir)\n",
    "            writer = tf.summary.FileWriter(logdir=logdir+\"/Tensorboard/\")\n",
    "            for epoch in range(n_epochs):\n",
    "                n_batches = int(len(train_images) / batch_size)\n",
    "                for _ in range(n_batches):\n",
    "                    batch = sess.run(train_images_dataset.next_element)\n",
    "                    # batch = batch.reshape([-1, 28*28])\n",
    "                    sess.run(optimizer, feed_dict={\n",
    "                             x_input: batch, x_target: batch})\n",
    "                    if _ % 50 == 0:\n",
    "                        summary, batch_loss = sess.run([summary_op, cycle_loss], feed_dict={\n",
    "                            x_input: batch, x_target: batch})\n",
    "                        writer.add_summary(summary, global_step=global_step)\n",
    "                        print(\"Loss: {}\".format(batch_loss))\n",
    "                        print(\"Epoch: {}, iteration: {}\".format(epoch, _))\n",
    "                    global_step += 1\n",
    "                saver.save(sess, save_path=logdir+\"/Saved_models/\",\n",
    "                           global_step=global_step)\n",
    "        else:\n",
    "            all_results = os.listdir(results_path)\n",
    "            all_results.sort()\n",
    "            print(all_results)\n",
    "            saver.restore(sess, save_path=tf.train.latest_checkpoint(\n",
    "                results_path + '/' + all_results[-1] + '/Saved_models/'))\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            n_batches = int(len(train_images) / batch_size)\n",
    "            for i in range(n_batches):\n",
    "                latent_code = sess.run(autoencoder.latent_code, feed_dict={\n",
    "                    x_input: train_images[batch_size*i:batch_size*(i+1)]})\n",
    "                plt.scatter(latent_code[:, 0],\n",
    "                            latent_code[:, 1], c=train_labels[batch_size*i:batch_size*(i+1)])\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "            generate_image_grid(sess, op=decoder_output)\n",
    "\n",
    "\n",
    "def generate_image_grid(sess, op):\n",
    "    \"\"\"\n",
    "    Generates a grid of images by passing a set of numbers to the decoder and getting its output.\n",
    "    :param sess: Tensorflow Session required to get the decoder output\n",
    "    :param op: Operation that needs to be called inorder to get the decoder output\n",
    "    :return: None, displays a matplotlib window with all the merged images.\n",
    "    \"\"\"\n",
    "    n = 10\n",
    "    x_points = np.linspace(-1, 1, n)\n",
    "    y_points = np.linspace(-1, 1, n)\n",
    "\n",
    "    nx, ny = len(x_points), len(y_points)\n",
    "    plt.subplot()\n",
    "    gs = gridspec.GridSpec(nx, ny, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i, g in enumerate(gs):\n",
    "        z = np.concatenate(([x_points[int(i / ny)]], [y_points[int(i % nx)]]))\n",
    "        z = np.reshape(z, (1, 2))\n",
    "        x = sess.run(op, feed_dict={decoder_input: z})\n",
    "        ax = plt.subplot(g)\n",
    "        img = np.array(x.tolist()).reshape(28, 28)\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_aspect('auto')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:07:52.479401Z",
     "start_time": "2018-12-18T11:04:19.997585Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始化自编码器\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 16)        80        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 32)          2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 128)         32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 44,272\n",
      "Trainable params: 43,792\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 4, 4, 64)          32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          8224      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 24, 24, 8)         1032      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         201       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 108,753\n",
      "Trainable params: 108,545\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Summary name Input Images is illegal; using Input_Images instead.\n",
      "INFO:tensorflow:Summary name Generated Images is illegal; using Generated_Images instead.\n",
      "<tf.Variable 'encoder/conv2d/kernel:0' shape=(2, 2, 1, 16) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d/bias:0' shape=(16,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization/gamma:0' shape=(16,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization/beta:0' shape=(16,) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d_1/kernel:0' shape=(2, 2, 16, 32) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d_1/bias:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization_1/gamma:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization_1/beta:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d_2/kernel:0' shape=(2, 2, 32, 64) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d_2/bias:0' shape=(64,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization_2/gamma:0' shape=(64,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization_2/beta:0' shape=(64,) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d_3/kernel:0' shape=(2, 2, 64, 128) dtype=float32>\n",
      "<tf.Variable 'encoder/conv2d_3/bias:0' shape=(128,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization_3/gamma:0' shape=(128,) dtype=float32>\n",
      "<tf.Variable 'encoder/batch_normalization_3/beta:0' shape=(128,) dtype=float32>\n",
      "<tf.Variable 'decoder/dense/kernel:0' shape=(128, 512) dtype=float32>\n",
      "<tf.Variable 'decoder/dense/bias:0' shape=(512,) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose/kernel:0' shape=(2, 2, 64, 128) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose/bias:0' shape=(64,) dtype=float32>\n",
      "<tf.Variable 'decoder/batch_normalization_4/gamma:0' shape=(64,) dtype=float32>\n",
      "<tf.Variable 'decoder/batch_normalization_4/beta:0' shape=(64,) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose_1/kernel:0' shape=(2, 2, 32, 64) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose_1/bias:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'decoder/batch_normalization_5/gamma:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'decoder/batch_normalization_5/beta:0' shape=(32,) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose_2/kernel:0' shape=(2, 2, 8, 32) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose_2/bias:0' shape=(8,) dtype=float32>\n",
      "<tf.Variable 'decoder/batch_normalization_6/gamma:0' shape=(8,) dtype=float32>\n",
      "<tf.Variable 'decoder/batch_normalization_6/beta:0' shape=(8,) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose_3/kernel:0' shape=(5, 5, 1, 8) dtype=float32>\n",
      "<tf.Variable 'decoder/conv2d_transpose_3/bias:0' shape=(1,) dtype=float32>\n",
      "[<tf.Variable 'decoder/dense/kernel:0' shape=(128, 512) dtype=float32>, <tf.Variable 'decoder/dense/bias:0' shape=(512,) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose/kernel:0' shape=(2, 2, 64, 128) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose/bias:0' shape=(64,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_4/gamma:0' shape=(64,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_4/beta:0' shape=(64,) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose_1/kernel:0' shape=(2, 2, 32, 64) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose_1/bias:0' shape=(32,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_5/gamma:0' shape=(32,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_5/beta:0' shape=(32,) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose_2/kernel:0' shape=(2, 2, 8, 32) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose_2/bias:0' shape=(8,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_6/gamma:0' shape=(8,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_6/beta:0' shape=(8,) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose_3/kernel:0' shape=(5, 5, 1, 8) dtype=float32>, <tf.Variable 'decoder/conv2d_transpose_3/bias:0' shape=(1,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_4/moving_mean:0' shape=(64,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_4/moving_variance:0' shape=(64,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_5/moving_mean:0' shape=(32,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_5/moving_variance:0' shape=(32,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_6/moving_mean:0' shape=(8,) dtype=float32>, <tf.Variable 'decoder/batch_normalization_6/moving_variance:0' shape=(8,) dtype=float32>]\n",
      "./Results/Autoencoder/2018-12-18 19h04m25s\n",
      "Loss: 6998.2080078125\n",
      "Epoch: 0, iteration: 0\n",
      "Loss: 3452.93310546875\n",
      "Epoch: 0, iteration: 50\n",
      "Loss: 2450.404052734375\n",
      "Epoch: 0, iteration: 100\n",
      "Loss: 1953.6109619140625\n",
      "Epoch: 0, iteration: 150\n",
      "Loss: 1595.248046875\n",
      "Epoch: 0, iteration: 200\n",
      "Loss: 1381.4547119140625\n",
      "Epoch: 0, iteration: 250\n",
      "Loss: 1457.074462890625\n",
      "Epoch: 0, iteration: 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1447.849365234375\n",
      "Epoch: 0, iteration: 350\n",
      "Loss: 1201.92578125\n",
      "Epoch: 0, iteration: 400\n",
      "Loss: 1317.0311279296875\n",
      "Epoch: 0, iteration: 450\n",
      "Loss: 1184.86572265625\n",
      "Epoch: 0, iteration: 500\n",
      "Loss: 1081.145751953125\n",
      "Epoch: 0, iteration: 550\n",
      "Loss: 992.0242309570312\n",
      "Epoch: 0, iteration: 600\n",
      "Loss: 979.3604736328125\n",
      "Epoch: 0, iteration: 650\n",
      "Loss: 1126.234375\n",
      "Epoch: 0, iteration: 700\n",
      "Loss: 1071.7698974609375\n",
      "Epoch: 0, iteration: 750\n",
      "Loss: 944.156005859375\n",
      "Epoch: 0, iteration: 800\n",
      "Loss: 892.1898193359375\n",
      "Epoch: 0, iteration: 850\n",
      "Loss: 986.4390869140625\n",
      "Epoch: 0, iteration: 900\n",
      "Loss: 1103.8692626953125\n",
      "Epoch: 1, iteration: 0\n",
      "Loss: 807.2877807617188\n",
      "Epoch: 1, iteration: 50\n",
      "Loss: 891.395263671875\n",
      "Epoch: 1, iteration: 100\n",
      "Loss: 953.83642578125\n",
      "Epoch: 1, iteration: 150\n",
      "Loss: 951.880126953125\n",
      "Epoch: 1, iteration: 200\n",
      "Loss: 858.0692138671875\n",
      "Epoch: 1, iteration: 250\n",
      "Loss: 1047.8665771484375\n",
      "Epoch: 1, iteration: 300\n",
      "Loss: 1032.69384765625\n",
      "Epoch: 1, iteration: 350\n",
      "Loss: 822.0460815429688\n",
      "Epoch: 1, iteration: 400\n",
      "Loss: 883.5841064453125\n",
      "Epoch: 1, iteration: 450\n",
      "Loss: 954.721923828125\n",
      "Epoch: 1, iteration: 500\n",
      "Loss: 833.2218627929688\n",
      "Epoch: 1, iteration: 550\n",
      "Loss: 828.9091186523438\n",
      "Epoch: 1, iteration: 600\n",
      "Loss: 782.8275756835938\n",
      "Epoch: 1, iteration: 650\n",
      "Loss: 826.5468139648438\n",
      "Epoch: 1, iteration: 700\n",
      "Loss: 868.1063232421875\n",
      "Epoch: 1, iteration: 750\n",
      "Loss: 925.434814453125\n",
      "Epoch: 1, iteration: 800\n",
      "Loss: 788.7503051757812\n",
      "Epoch: 1, iteration: 850\n",
      "Loss: 801.30712890625\n",
      "Epoch: 1, iteration: 900\n",
      "Loss: 926.3820190429688\n",
      "Epoch: 2, iteration: 0\n",
      "Loss: 703.8403930664062\n",
      "Epoch: 2, iteration: 50\n",
      "Loss: 786.8165893554688\n",
      "Epoch: 2, iteration: 100\n",
      "Loss: 823.6148071289062\n",
      "Epoch: 2, iteration: 150\n",
      "Loss: 1022.6063232421875\n",
      "Epoch: 2, iteration: 200\n",
      "Loss: 735.839599609375\n",
      "Epoch: 2, iteration: 250\n",
      "Loss: 897.4166259765625\n",
      "Epoch: 2, iteration: 300\n",
      "Loss: 896.0143432617188\n",
      "Epoch: 2, iteration: 350\n",
      "Loss: 796.0875244140625\n",
      "Epoch: 2, iteration: 400\n",
      "Loss: 838.2849731445312\n",
      "Epoch: 2, iteration: 450\n",
      "Loss: 884.9536743164062\n",
      "Epoch: 2, iteration: 500\n",
      "Loss: 788.6854248046875\n",
      "Epoch: 2, iteration: 550\n",
      "Loss: 849.5518188476562\n",
      "Epoch: 2, iteration: 600\n",
      "Loss: 720.7225952148438\n",
      "Epoch: 2, iteration: 650\n",
      "Loss: 826.4944458007812\n",
      "Epoch: 2, iteration: 700\n",
      "Loss: 732.79736328125\n",
      "Epoch: 2, iteration: 750\n",
      "Loss: 871.3526611328125\n",
      "Epoch: 2, iteration: 800\n",
      "Loss: 795.62451171875\n",
      "Epoch: 2, iteration: 850\n",
      "Loss: 739.6188354492188\n",
      "Epoch: 2, iteration: 900\n",
      "Loss: 917.8163452148438\n",
      "Epoch: 3, iteration: 0\n",
      "Loss: 615.3348999023438\n",
      "Epoch: 3, iteration: 50\n",
      "Loss: 826.7164916992188\n",
      "Epoch: 3, iteration: 100\n",
      "Loss: 922.3765869140625\n",
      "Epoch: 3, iteration: 150\n",
      "Loss: 1032.4443359375\n",
      "Epoch: 3, iteration: 200\n",
      "Loss: 812.8573608398438\n",
      "Epoch: 3, iteration: 250\n",
      "Loss: 790.6340942382812\n",
      "Epoch: 3, iteration: 300\n",
      "Loss: 841.0526733398438\n",
      "Epoch: 3, iteration: 350\n",
      "Loss: 797.73291015625\n",
      "Epoch: 3, iteration: 400\n",
      "Loss: 841.920654296875\n",
      "Epoch: 3, iteration: 450\n",
      "Loss: 869.7041625976562\n",
      "Epoch: 3, iteration: 500\n",
      "Loss: 792.965087890625\n",
      "Epoch: 3, iteration: 550\n",
      "Loss: 880.2885131835938\n",
      "Epoch: 3, iteration: 600\n",
      "Loss: 674.140869140625\n",
      "Epoch: 3, iteration: 650\n",
      "Loss: 898.6312866210938\n",
      "Epoch: 3, iteration: 700\n",
      "Loss: 782.9093017578125\n",
      "Epoch: 3, iteration: 750\n",
      "Loss: 760.3474731445312\n",
      "Epoch: 3, iteration: 800\n",
      "Loss: 749.5177612304688\n",
      "Epoch: 3, iteration: 850\n",
      "Loss: 790.190185546875\n",
      "Epoch: 3, iteration: 900\n",
      "Loss: 797.6724853515625\n",
      "Epoch: 4, iteration: 0\n",
      "Loss: 658.3634643554688\n",
      "Epoch: 4, iteration: 50\n",
      "Loss: 764.98388671875\n",
      "Epoch: 4, iteration: 100\n",
      "Loss: 1057.165283203125\n",
      "Epoch: 4, iteration: 150\n",
      "Loss: 852.5166015625\n",
      "Epoch: 4, iteration: 200\n",
      "Loss: 826.8981323242188\n",
      "Epoch: 4, iteration: 250\n",
      "Loss: 707.084716796875\n",
      "Epoch: 4, iteration: 300\n",
      "Loss: 795.2215576171875\n",
      "Epoch: 4, iteration: 350\n",
      "Loss: 756.8518676757812\n",
      "Epoch: 4, iteration: 400\n",
      "Loss: 781.1351928710938\n",
      "Epoch: 4, iteration: 450\n",
      "Loss: 807.6151123046875\n",
      "Epoch: 4, iteration: 500\n",
      "Loss: 704.3851318359375\n",
      "Epoch: 4, iteration: 550\n",
      "Loss: 799.70849609375\n",
      "Epoch: 4, iteration: 600\n",
      "Loss: 656.722900390625\n",
      "Epoch: 4, iteration: 650\n",
      "Loss: 741.6553955078125\n",
      "Epoch: 4, iteration: 700\n",
      "Loss: 730.0797729492188\n",
      "Epoch: 4, iteration: 750\n",
      "Loss: 704.0403442382812\n",
      "Epoch: 4, iteration: 800\n",
      "Loss: 726.7496948242188\n",
      "Epoch: 4, iteration: 850\n",
      "Loss: 792.858642578125\n",
      "Epoch: 4, iteration: 900\n",
      "Loss: 648.552490234375\n",
      "Epoch: 5, iteration: 0\n",
      "Loss: 759.8760375976562\n",
      "Epoch: 5, iteration: 50\n",
      "Loss: 655.8041381835938\n",
      "Epoch: 5, iteration: 100\n",
      "Loss: 881.3723754882812\n",
      "Epoch: 5, iteration: 150\n",
      "Loss: 773.2632446289062\n",
      "Epoch: 5, iteration: 200\n",
      "Loss: 697.6642456054688\n",
      "Epoch: 5, iteration: 250\n",
      "Loss: 666.6380615234375\n",
      "Epoch: 5, iteration: 300\n",
      "Loss: 777.008056640625\n",
      "Epoch: 5, iteration: 350\n",
      "Loss: 701.5731201171875\n",
      "Epoch: 5, iteration: 400\n",
      "Loss: 798.2705688476562\n",
      "Epoch: 5, iteration: 450\n",
      "Loss: 692.8477172851562\n",
      "Epoch: 5, iteration: 500\n",
      "Loss: 686.9812622070312\n",
      "Epoch: 5, iteration: 550\n",
      "Loss: 708.3770751953125\n",
      "Epoch: 5, iteration: 600\n",
      "Loss: 656.2866821289062\n",
      "Epoch: 5, iteration: 650\n",
      "Loss: 580.5829467773438\n",
      "Epoch: 5, iteration: 700\n",
      "Loss: 611.161376953125\n",
      "Epoch: 5, iteration: 750\n",
      "Loss: 667.8509521484375\n",
      "Epoch: 5, iteration: 800\n",
      "Loss: 666.2908325195312\n",
      "Epoch: 5, iteration: 850\n",
      "Loss: 710.2578735351562\n",
      "Epoch: 5, iteration: 900\n",
      "Loss: 723.065185546875\n",
      "Epoch: 6, iteration: 0\n",
      "Loss: 782.800537109375\n",
      "Epoch: 6, iteration: 50\n",
      "Loss: 663.95947265625\n",
      "Epoch: 6, iteration: 100\n",
      "Loss: 812.950439453125\n",
      "Epoch: 6, iteration: 150\n",
      "Loss: 746.2349243164062\n",
      "Epoch: 6, iteration: 200\n",
      "Loss: 766.06103515625\n",
      "Epoch: 6, iteration: 250\n",
      "Loss: 691.2667236328125\n",
      "Epoch: 6, iteration: 300\n",
      "Loss: 785.4666137695312\n",
      "Epoch: 6, iteration: 350\n",
      "Loss: 705.168212890625\n",
      "Epoch: 6, iteration: 400\n",
      "Loss: 875.6256103515625\n",
      "Epoch: 6, iteration: 450\n",
      "Loss: 777.6809692382812\n",
      "Epoch: 6, iteration: 500\n",
      "Loss: 719.9927978515625\n",
      "Epoch: 6, iteration: 550\n",
      "Loss: 736.1101684570312\n",
      "Epoch: 6, iteration: 600\n",
      "Loss: 790.751220703125\n",
      "Epoch: 6, iteration: 650\n",
      "Loss: 625.7963256835938\n",
      "Epoch: 6, iteration: 700\n",
      "Loss: 654.4334106445312\n",
      "Epoch: 6, iteration: 750\n",
      "Loss: 586.2421264648438\n",
      "Epoch: 6, iteration: 800\n",
      "Loss: 654.2831420898438\n",
      "Epoch: 6, iteration: 850\n",
      "Loss: 720.526123046875\n",
      "Epoch: 6, iteration: 900\n",
      "Loss: 744.5394897460938\n",
      "Epoch: 7, iteration: 0\n",
      "Loss: 641.3795166015625\n",
      "Epoch: 7, iteration: 50\n",
      "Loss: 694.0150146484375\n",
      "Epoch: 7, iteration: 100\n",
      "Loss: 907.7731323242188\n",
      "Epoch: 7, iteration: 150\n",
      "Loss: 754.276611328125\n",
      "Epoch: 7, iteration: 200\n",
      "Loss: 805.07177734375\n",
      "Epoch: 7, iteration: 250\n",
      "Loss: 703.2520141601562\n",
      "Epoch: 7, iteration: 300\n",
      "Loss: 808.5518188476562\n",
      "Epoch: 7, iteration: 350\n",
      "Loss: 751.9188232421875\n",
      "Epoch: 7, iteration: 400\n",
      "Loss: 737.3346557617188\n",
      "Epoch: 7, iteration: 450\n",
      "Loss: 888.1072387695312\n",
      "Epoch: 7, iteration: 500\n",
      "Loss: 615.2625732421875\n",
      "Epoch: 7, iteration: 550\n",
      "Loss: 717.4468994140625\n",
      "Epoch: 7, iteration: 600\n",
      "Loss: 831.4326171875\n",
      "Epoch: 7, iteration: 650\n",
      "Loss: 633.8873291015625\n",
      "Epoch: 7, iteration: 700\n",
      "Loss: 734.1541137695312\n",
      "Epoch: 7, iteration: 750\n",
      "Loss: 563.0269165039062\n",
      "Epoch: 7, iteration: 800\n",
      "Loss: 701.3340454101562\n",
      "Epoch: 7, iteration: 850\n",
      "Loss: 718.2556762695312\n",
      "Epoch: 7, iteration: 900\n",
      "Loss: 740.76513671875\n",
      "Epoch: 8, iteration: 0\n",
      "Loss: 530.9274291992188\n",
      "Epoch: 8, iteration: 50\n",
      "Loss: 667.6361694335938\n",
      "Epoch: 8, iteration: 100\n",
      "Loss: 773.8447265625\n",
      "Epoch: 8, iteration: 150\n",
      "Loss: 749.3637084960938\n",
      "Epoch: 8, iteration: 200\n",
      "Loss: 710.0612182617188\n",
      "Epoch: 8, iteration: 250\n",
      "Loss: 702.8619384765625\n",
      "Epoch: 8, iteration: 300\n",
      "Loss: 826.3418579101562\n",
      "Epoch: 8, iteration: 350\n",
      "Loss: 713.4818115234375\n",
      "Epoch: 8, iteration: 400\n",
      "Loss: 734.4012451171875\n",
      "Epoch: 8, iteration: 450\n",
      "Loss: 805.7890014648438\n",
      "Epoch: 8, iteration: 500\n",
      "Loss: 614.3338012695312\n",
      "Epoch: 8, iteration: 550\n",
      "Loss: 727.8987426757812\n",
      "Epoch: 8, iteration: 600\n",
      "Loss: 778.6286010742188\n",
      "Epoch: 8, iteration: 650\n",
      "Loss: 654.7611083984375\n",
      "Epoch: 8, iteration: 700\n",
      "Loss: 742.92822265625\n",
      "Epoch: 8, iteration: 750\n",
      "Loss: 607.2890625\n",
      "Epoch: 8, iteration: 800\n",
      "Loss: 720.78466796875\n",
      "Epoch: 8, iteration: 850\n",
      "Loss: 645.980224609375\n",
      "Epoch: 8, iteration: 900\n",
      "Loss: 729.81298828125\n",
      "Epoch: 9, iteration: 0\n",
      "Loss: 582.6078491210938\n",
      "Epoch: 9, iteration: 50\n",
      "Loss: 693.9549560546875\n",
      "Epoch: 9, iteration: 100\n",
      "Loss: 657.6026000976562\n",
      "Epoch: 9, iteration: 150\n",
      "Loss: 711.811279296875\n",
      "Epoch: 9, iteration: 200\n",
      "Loss: 661.3729248046875\n",
      "Epoch: 9, iteration: 250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 660.4075317382812\n",
      "Epoch: 9, iteration: 300\n",
      "Loss: 869.2568359375\n",
      "Epoch: 9, iteration: 350\n",
      "Loss: 752.05712890625\n",
      "Epoch: 9, iteration: 400\n",
      "Loss: 790.4598388671875\n",
      "Epoch: 9, iteration: 450\n",
      "Loss: 710.7951049804688\n",
      "Epoch: 9, iteration: 500\n",
      "Loss: 659.1510009765625\n",
      "Epoch: 9, iteration: 550\n",
      "Loss: 734.02685546875\n",
      "Epoch: 9, iteration: 600\n",
      "Loss: 759.9002075195312\n",
      "Epoch: 9, iteration: 650\n",
      "Loss: 666.4736328125\n",
      "Epoch: 9, iteration: 700\n",
      "Loss: 776.3168334960938\n",
      "Epoch: 9, iteration: 750\n",
      "Loss: 618.6172485351562\n",
      "Epoch: 9, iteration: 800\n",
      "Loss: 662.5156860351562\n",
      "Epoch: 9, iteration: 850\n",
      "Loss: 598.1445922851562\n",
      "Epoch: 9, iteration: 900\n",
      "Loss: 760.3793334960938\n",
      "Epoch: 10, iteration: 0\n",
      "Loss: 691.520751953125\n",
      "Epoch: 10, iteration: 50\n",
      "Loss: 703.3088989257812\n",
      "Epoch: 10, iteration: 100\n",
      "Loss: 667.0458374023438\n",
      "Epoch: 10, iteration: 150\n",
      "Loss: 664.3689575195312\n",
      "Epoch: 10, iteration: 200\n",
      "Loss: 698.7098388671875\n",
      "Epoch: 10, iteration: 250\n",
      "Loss: 628.03515625\n",
      "Epoch: 10, iteration: 300\n",
      "Loss: 954.9398803710938\n",
      "Epoch: 10, iteration: 350\n",
      "Loss: 854.5336303710938\n",
      "Epoch: 10, iteration: 400\n",
      "Loss: 708.075439453125\n",
      "Epoch: 10, iteration: 450\n",
      "Loss: 802.4288940429688\n",
      "Epoch: 10, iteration: 500\n",
      "Loss: 675.99462890625\n",
      "Epoch: 10, iteration: 550\n",
      "Loss: 682.5398559570312\n",
      "Epoch: 10, iteration: 600\n",
      "Loss: 831.3779296875\n",
      "Epoch: 10, iteration: 650\n",
      "Loss: 685.0880126953125\n",
      "Epoch: 10, iteration: 700\n",
      "Loss: 780.432861328125\n",
      "Epoch: 10, iteration: 750\n",
      "Loss: 603.99072265625\n",
      "Epoch: 10, iteration: 800\n",
      "Loss: 640.9556274414062\n",
      "Epoch: 10, iteration: 850\n",
      "Loss: 662.6806640625\n",
      "Epoch: 10, iteration: 900\n",
      "Loss: 762.7530517578125\n",
      "Epoch: 11, iteration: 0\n",
      "Loss: 735.7469482421875\n",
      "Epoch: 11, iteration: 50\n",
      "Loss: 711.8661499023438\n",
      "Epoch: 11, iteration: 100\n",
      "Loss: 641.4901123046875\n",
      "Epoch: 11, iteration: 150\n",
      "Loss: 701.5083618164062\n",
      "Epoch: 11, iteration: 200\n",
      "Loss: 708.785400390625\n",
      "Epoch: 11, iteration: 250\n",
      "Loss: 640.3591918945312\n",
      "Epoch: 11, iteration: 300\n",
      "Loss: 923.7692260742188\n",
      "Epoch: 11, iteration: 350\n",
      "Loss: 713.2650756835938\n",
      "Epoch: 11, iteration: 400\n",
      "Loss: 777.6708984375\n",
      "Epoch: 11, iteration: 450\n",
      "Loss: 831.7304077148438\n",
      "Epoch: 11, iteration: 500\n",
      "Loss: 733.2037353515625\n",
      "Epoch: 11, iteration: 550\n",
      "Loss: 692.5173950195312\n",
      "Epoch: 11, iteration: 600\n",
      "Loss: 792.4743041992188\n",
      "Epoch: 11, iteration: 650\n",
      "Loss: 784.7015991210938\n",
      "Epoch: 11, iteration: 700\n",
      "Loss: 829.1890869140625\n",
      "Epoch: 11, iteration: 750\n",
      "Loss: 534.8341674804688\n",
      "Epoch: 11, iteration: 800\n",
      "Loss: 647.042236328125\n",
      "Epoch: 11, iteration: 850\n",
      "Loss: 722.1171875\n",
      "Epoch: 11, iteration: 900\n",
      "Loss: 736.32470703125\n",
      "Epoch: 12, iteration: 0\n",
      "Loss: 715.9234619140625\n",
      "Epoch: 12, iteration: 50\n",
      "Loss: 692.8580932617188\n",
      "Epoch: 12, iteration: 100\n",
      "Loss: 533.2158203125\n",
      "Epoch: 12, iteration: 150\n",
      "Loss: 687.5750732421875\n",
      "Epoch: 12, iteration: 200\n",
      "Loss: 721.160400390625\n",
      "Epoch: 12, iteration: 250\n",
      "Loss: 662.0833740234375\n",
      "Epoch: 12, iteration: 300\n",
      "Loss: 870.080810546875\n",
      "Epoch: 12, iteration: 350\n",
      "Loss: 596.8582153320312\n",
      "Epoch: 12, iteration: 400\n",
      "Loss: 761.40869140625\n",
      "Epoch: 12, iteration: 450\n",
      "Loss: 760.0971069335938\n",
      "Epoch: 12, iteration: 500\n",
      "Loss: 748.434814453125\n",
      "Epoch: 12, iteration: 550\n",
      "Loss: 679.9611206054688\n",
      "Epoch: 12, iteration: 600\n",
      "Loss: 667.6500854492188\n",
      "Epoch: 12, iteration: 650\n",
      "Loss: 776.8531494140625\n",
      "Epoch: 12, iteration: 700\n",
      "Loss: 870.570556640625\n",
      "Epoch: 12, iteration: 750\n",
      "Loss: 565.0000610351562\n",
      "Epoch: 12, iteration: 800\n",
      "Loss: 706.7296142578125\n",
      "Epoch: 12, iteration: 850\n",
      "Loss: 719.0843505859375\n",
      "Epoch: 12, iteration: 900\n",
      "Loss: 651.0914916992188\n",
      "Epoch: 13, iteration: 0\n",
      "Loss: 713.4451293945312\n",
      "Epoch: 13, iteration: 50\n",
      "Loss: 630.8773803710938\n",
      "Epoch: 13, iteration: 100\n",
      "Loss: 605.4559326171875\n",
      "Epoch: 13, iteration: 150\n",
      "Loss: 711.4548950195312\n",
      "Epoch: 13, iteration: 200\n",
      "Loss: 704.8731079101562\n",
      "Epoch: 13, iteration: 250\n",
      "Loss: 664.9468383789062\n",
      "Epoch: 13, iteration: 300\n",
      "Loss: 725.5726928710938\n",
      "Epoch: 13, iteration: 350\n",
      "Loss: 599.4398193359375\n",
      "Epoch: 13, iteration: 400\n",
      "Loss: 758.4547119140625\n",
      "Epoch: 13, iteration: 450\n",
      "Loss: 683.5888671875\n",
      "Epoch: 13, iteration: 500\n",
      "Loss: 718.9678955078125\n",
      "Epoch: 13, iteration: 550\n",
      "Loss: 666.95947265625\n",
      "Epoch: 13, iteration: 600\n",
      "Loss: 680.7305297851562\n",
      "Epoch: 13, iteration: 650\n",
      "Loss: 666.1015625\n",
      "Epoch: 13, iteration: 700\n",
      "Loss: 895.2589111328125\n",
      "Epoch: 13, iteration: 750\n",
      "Loss: 626.5164794921875\n",
      "Epoch: 13, iteration: 800\n",
      "Loss: 745.64453125\n",
      "Epoch: 13, iteration: 850\n",
      "Loss: 749.2164916992188\n",
      "Epoch: 13, iteration: 900\n",
      "Loss: 650.2388305664062\n",
      "Epoch: 14, iteration: 0\n",
      "Loss: 796.5869140625\n",
      "Epoch: 14, iteration: 50\n",
      "Loss: 723.750732421875\n",
      "Epoch: 14, iteration: 100\n",
      "Loss: 700.8590698242188\n",
      "Epoch: 14, iteration: 150\n",
      "Loss: 855.0499267578125\n",
      "Epoch: 14, iteration: 200\n",
      "Loss: 627.583251953125\n",
      "Epoch: 14, iteration: 250\n",
      "Loss: 657.2189331054688\n",
      "Epoch: 14, iteration: 300\n",
      "Loss: 585.8414306640625\n",
      "Epoch: 14, iteration: 350\n",
      "Loss: 602.0739135742188\n",
      "Epoch: 14, iteration: 400\n",
      "Loss: 847.3119506835938\n",
      "Epoch: 14, iteration: 450\n",
      "Loss: 620.1331176757812\n",
      "Epoch: 14, iteration: 500\n",
      "Loss: 677.1254272460938\n",
      "Epoch: 14, iteration: 550\n",
      "Loss: 658.528564453125\n",
      "Epoch: 14, iteration: 600\n",
      "Loss: 627.2587890625\n",
      "Epoch: 14, iteration: 650\n",
      "Loss: 656.4850463867188\n",
      "Epoch: 14, iteration: 700\n",
      "Loss: 916.5379638671875\n",
      "Epoch: 14, iteration: 750\n",
      "Loss: 590.7339477539062\n",
      "Epoch: 14, iteration: 800\n",
      "Loss: 719.5403442382812\n",
      "Epoch: 14, iteration: 850\n",
      "Loss: 750.621826171875\n",
      "Epoch: 14, iteration: 900\n",
      "Loss: 525.4624633789062\n",
      "Epoch: 15, iteration: 0\n",
      "Loss: 944.0677490234375\n",
      "Epoch: 15, iteration: 50\n",
      "Loss: 706.4337768554688\n",
      "Epoch: 15, iteration: 100\n",
      "Loss: 616.7495727539062\n",
      "Epoch: 15, iteration: 150\n",
      "Loss: 825.2064819335938\n",
      "Epoch: 15, iteration: 200\n",
      "Loss: 638.6648559570312\n",
      "Epoch: 15, iteration: 250\n",
      "Loss: 766.73583984375\n",
      "Epoch: 15, iteration: 300\n",
      "Loss: 688.9574584960938\n",
      "Epoch: 15, iteration: 350\n",
      "Loss: 620.5839233398438\n",
      "Epoch: 15, iteration: 400\n",
      "Loss: 722.5621948242188\n",
      "Epoch: 15, iteration: 450\n",
      "Loss: 595.4354248046875\n",
      "Epoch: 15, iteration: 500\n",
      "Loss: 680.3767700195312\n",
      "Epoch: 15, iteration: 550\n",
      "Loss: 596.5189819335938\n",
      "Epoch: 15, iteration: 600\n",
      "Loss: 586.1510009765625\n",
      "Epoch: 15, iteration: 650\n",
      "Loss: 733.9568481445312\n",
      "Epoch: 15, iteration: 700\n",
      "Loss: 730.9072875976562\n",
      "Epoch: 15, iteration: 750\n",
      "Loss: 589.7532958984375\n",
      "Epoch: 15, iteration: 800\n",
      "Loss: 668.7697143554688\n",
      "Epoch: 15, iteration: 850\n",
      "Loss: 676.8585205078125\n",
      "Epoch: 15, iteration: 900\n",
      "Loss: 474.01434326171875\n",
      "Epoch: 16, iteration: 0\n",
      "Loss: 798.3051147460938\n",
      "Epoch: 16, iteration: 50\n",
      "Loss: 622.2359619140625\n",
      "Epoch: 16, iteration: 100\n",
      "Loss: 573.03662109375\n",
      "Epoch: 16, iteration: 150\n",
      "Loss: 738.8707885742188\n",
      "Epoch: 16, iteration: 200\n",
      "Loss: 685.0659790039062\n",
      "Epoch: 16, iteration: 250\n",
      "Loss: 720.6527709960938\n",
      "Epoch: 16, iteration: 300\n",
      "Loss: 696.0640869140625\n",
      "Epoch: 16, iteration: 350\n",
      "Loss: 612.05908203125\n",
      "Epoch: 16, iteration: 400\n",
      "Loss: 679.534912109375\n",
      "Epoch: 16, iteration: 450\n",
      "Loss: 660.4854125976562\n",
      "Epoch: 16, iteration: 500\n",
      "Loss: 673.4185180664062\n",
      "Epoch: 16, iteration: 550\n",
      "Loss: 633.7926635742188\n",
      "Epoch: 16, iteration: 600\n",
      "Loss: 593.2444458007812\n",
      "Epoch: 16, iteration: 650\n",
      "Loss: 789.8692626953125\n",
      "Epoch: 16, iteration: 700\n",
      "Loss: 637.5784301757812\n",
      "Epoch: 16, iteration: 750\n",
      "Loss: 660.2572631835938\n",
      "Epoch: 16, iteration: 800\n",
      "Loss: 702.2544555664062\n",
      "Epoch: 16, iteration: 850\n",
      "Loss: 628.5592651367188\n",
      "Epoch: 16, iteration: 900\n",
      "Loss: 672.74169921875\n",
      "Epoch: 17, iteration: 0\n",
      "Loss: 615.6920166015625\n",
      "Epoch: 17, iteration: 50\n",
      "Loss: 588.7266845703125\n",
      "Epoch: 17, iteration: 100\n",
      "Loss: 572.3502197265625\n",
      "Epoch: 17, iteration: 150\n",
      "Loss: 841.3365478515625\n",
      "Epoch: 17, iteration: 200\n",
      "Loss: 684.6128540039062\n",
      "Epoch: 17, iteration: 250\n",
      "Loss: 671.175048828125\n",
      "Epoch: 17, iteration: 300\n",
      "Loss: 667.297119140625\n",
      "Epoch: 17, iteration: 350\n",
      "Loss: 646.7012939453125\n",
      "Epoch: 17, iteration: 400\n",
      "Loss: 755.9534301757812\n",
      "Epoch: 17, iteration: 450\n",
      "Loss: 701.0831298828125\n",
      "Epoch: 17, iteration: 500\n",
      "Loss: 721.2962646484375\n",
      "Epoch: 17, iteration: 550\n",
      "Loss: 715.2245483398438\n",
      "Epoch: 17, iteration: 600\n",
      "Loss: 586.8164672851562\n",
      "Epoch: 17, iteration: 650\n",
      "Loss: 739.1531982421875\n",
      "Epoch: 17, iteration: 700\n",
      "Loss: 638.5609741210938\n",
      "Epoch: 17, iteration: 750\n",
      "Loss: 708.4447021484375\n",
      "Epoch: 17, iteration: 800\n",
      "Loss: 810.6638793945312\n",
      "Epoch: 17, iteration: 850\n",
      "Loss: 589.131103515625\n",
      "Epoch: 17, iteration: 900\n",
      "Loss: 1094.0474853515625\n",
      "Epoch: 18, iteration: 0\n",
      "Loss: 676.514892578125\n",
      "Epoch: 18, iteration: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 543.5093994140625\n",
      "Epoch: 18, iteration: 100\n",
      "Loss: 580.6900634765625\n",
      "Epoch: 18, iteration: 150\n",
      "Loss: 889.503173828125\n",
      "Epoch: 18, iteration: 200\n",
      "Loss: 576.01953125\n",
      "Epoch: 18, iteration: 250\n",
      "Loss: 746.55419921875\n",
      "Epoch: 18, iteration: 300\n",
      "Loss: 635.015869140625\n",
      "Epoch: 18, iteration: 350\n",
      "Loss: 617.1424560546875\n",
      "Epoch: 18, iteration: 400\n",
      "Loss: 684.1976928710938\n",
      "Epoch: 18, iteration: 450\n",
      "Loss: 603.2988891601562\n",
      "Epoch: 18, iteration: 500\n",
      "Loss: 732.8748168945312\n",
      "Epoch: 18, iteration: 550\n",
      "Loss: 712.723876953125\n",
      "Epoch: 18, iteration: 600\n",
      "Loss: 701.1771240234375\n",
      "Epoch: 18, iteration: 650\n",
      "Loss: 748.9083251953125\n",
      "Epoch: 18, iteration: 700\n",
      "Loss: 724.4213256835938\n",
      "Epoch: 18, iteration: 750\n",
      "Loss: 647.5684204101562\n",
      "Epoch: 18, iteration: 800\n",
      "Loss: 764.0137939453125\n",
      "Epoch: 18, iteration: 850\n",
      "Loss: 519.8101806640625\n",
      "Epoch: 18, iteration: 900\n",
      "Loss: 1255.9041748046875\n",
      "Epoch: 19, iteration: 0\n",
      "Loss: 615.8695678710938\n",
      "Epoch: 19, iteration: 50\n",
      "Loss: 600.3492431640625\n",
      "Epoch: 19, iteration: 100\n",
      "Loss: 641.224853515625\n",
      "Epoch: 19, iteration: 150\n",
      "Loss: 743.8935546875\n",
      "Epoch: 19, iteration: 200\n",
      "Loss: 573.8320922851562\n",
      "Epoch: 19, iteration: 250\n",
      "Loss: 754.0302124023438\n",
      "Epoch: 19, iteration: 300\n",
      "Loss: 602.4266357421875\n",
      "Epoch: 19, iteration: 350\n",
      "Loss: 634.19189453125\n",
      "Epoch: 19, iteration: 400\n",
      "Loss: 696.2117919921875\n",
      "Epoch: 19, iteration: 450\n",
      "Loss: 583.0401611328125\n",
      "Epoch: 19, iteration: 500\n",
      "Loss: 665.7903442382812\n",
      "Epoch: 19, iteration: 550\n",
      "Loss: 678.4940795898438\n",
      "Epoch: 19, iteration: 600\n",
      "Loss: 690.4095458984375\n",
      "Epoch: 19, iteration: 650\n",
      "Loss: 669.1723022460938\n",
      "Epoch: 19, iteration: 700\n",
      "Loss: 791.7323608398438\n",
      "Epoch: 19, iteration: 750\n",
      "Loss: 599.9119873046875\n",
      "Epoch: 19, iteration: 800\n",
      "Loss: 625.0701293945312\n",
      "Epoch: 19, iteration: 850\n",
      "Loss: 583.4961547851562\n",
      "Epoch: 19, iteration: 900\n",
      "Loss: 1414.189453125\n",
      "Epoch: 20, iteration: 0\n",
      "Loss: 570.0984497070312\n",
      "Epoch: 20, iteration: 50\n",
      "Loss: 624.291015625\n",
      "Epoch: 20, iteration: 100\n",
      "Loss: 635.8850708007812\n",
      "Epoch: 20, iteration: 150\n",
      "Loss: 700.8704833984375\n",
      "Epoch: 20, iteration: 200\n",
      "Loss: 625.07861328125\n",
      "Epoch: 20, iteration: 250\n",
      "Loss: 796.2677612304688\n",
      "Epoch: 20, iteration: 300\n",
      "Loss: 719.4979248046875\n",
      "Epoch: 20, iteration: 350\n",
      "Loss: 591.1914672851562\n",
      "Epoch: 20, iteration: 400\n",
      "Loss: 736.2056884765625\n",
      "Epoch: 20, iteration: 450\n",
      "Loss: 635.9853515625\n",
      "Epoch: 20, iteration: 500\n",
      "Loss: 626.7198486328125\n",
      "Epoch: 20, iteration: 550\n",
      "Loss: 768.7565307617188\n",
      "Epoch: 20, iteration: 600\n",
      "Loss: 588.1888427734375\n",
      "Epoch: 20, iteration: 650\n",
      "Loss: 601.0614013671875\n",
      "Epoch: 20, iteration: 700\n",
      "Loss: 789.8485107421875\n",
      "Epoch: 20, iteration: 750\n",
      "Loss: 628.0968627929688\n",
      "Epoch: 20, iteration: 800\n",
      "Loss: 545.75341796875\n",
      "Epoch: 20, iteration: 850\n",
      "Loss: 656.7985229492188\n",
      "Epoch: 20, iteration: 900\n",
      "Loss: 1283.725830078125\n",
      "Epoch: 21, iteration: 0\n",
      "Loss: 616.431396484375\n",
      "Epoch: 21, iteration: 50\n",
      "Loss: 676.553955078125\n",
      "Epoch: 21, iteration: 100\n",
      "Loss: 666.919677734375\n",
      "Epoch: 21, iteration: 150\n",
      "Loss: 660.0128173828125\n",
      "Epoch: 21, iteration: 200\n",
      "Loss: 539.9906616210938\n",
      "Epoch: 21, iteration: 250\n",
      "Loss: 779.7559204101562\n",
      "Epoch: 21, iteration: 300\n",
      "Loss: 675.6643676757812\n",
      "Epoch: 21, iteration: 350\n",
      "Loss: 482.5151062011719\n",
      "Epoch: 21, iteration: 400\n",
      "Loss: 670.0399169921875\n",
      "Epoch: 21, iteration: 450\n",
      "Loss: 586.76025390625\n",
      "Epoch: 21, iteration: 500\n",
      "Loss: 621.0018920898438\n",
      "Epoch: 21, iteration: 550\n",
      "Loss: 862.1681518554688\n",
      "Epoch: 21, iteration: 600\n",
      "Loss: 624.5418090820312\n",
      "Epoch: 21, iteration: 650\n",
      "Loss: 607.8607177734375\n",
      "Epoch: 21, iteration: 700\n",
      "Loss: 692.6293334960938\n",
      "Epoch: 21, iteration: 750\n",
      "Loss: 651.51416015625\n",
      "Epoch: 21, iteration: 800\n",
      "Loss: 636.4573364257812\n",
      "Epoch: 21, iteration: 850\n",
      "Loss: 619.0818481445312\n",
      "Epoch: 21, iteration: 900\n",
      "Loss: 837.2133178710938\n",
      "Epoch: 22, iteration: 0\n",
      "Loss: 665.8805541992188\n",
      "Epoch: 22, iteration: 50\n",
      "Loss: 695.739013671875\n",
      "Epoch: 22, iteration: 100\n",
      "Loss: 696.2115478515625\n",
      "Epoch: 22, iteration: 150\n",
      "Loss: 533.8982543945312\n",
      "Epoch: 22, iteration: 200\n",
      "Loss: 507.0290222167969\n",
      "Epoch: 22, iteration: 250\n",
      "Loss: 712.6382446289062\n",
      "Epoch: 22, iteration: 300\n",
      "Loss: 553.9061889648438\n",
      "Epoch: 22, iteration: 350\n",
      "Loss: 543.6400146484375\n",
      "Epoch: 22, iteration: 400\n",
      "Loss: 631.2304077148438\n",
      "Epoch: 22, iteration: 450\n",
      "Loss: 638.6200561523438\n",
      "Epoch: 22, iteration: 500\n",
      "Loss: 660.7891235351562\n",
      "Epoch: 22, iteration: 550\n",
      "Loss: 725.7732543945312\n",
      "Epoch: 22, iteration: 600\n",
      "Loss: 603.69482421875\n",
      "Epoch: 22, iteration: 650\n",
      "Loss: 580.1883544921875\n",
      "Epoch: 22, iteration: 700\n",
      "Loss: 659.777099609375\n",
      "Epoch: 22, iteration: 750\n",
      "Loss: 707.73583984375\n",
      "Epoch: 22, iteration: 800\n",
      "Loss: 688.9591674804688\n",
      "Epoch: 22, iteration: 850\n",
      "Loss: 584.2634887695312\n",
      "Epoch: 22, iteration: 900\n",
      "Loss: 739.2265625\n",
      "Epoch: 23, iteration: 0\n",
      "Loss: 713.6428833007812\n",
      "Epoch: 23, iteration: 50\n",
      "Loss: 631.678955078125\n",
      "Epoch: 23, iteration: 100\n",
      "Loss: 642.2057495117188\n",
      "Epoch: 23, iteration: 150\n",
      "Loss: 640.1032104492188\n",
      "Epoch: 23, iteration: 200\n",
      "Loss: 565.6807861328125\n",
      "Epoch: 23, iteration: 250\n",
      "Loss: 660.0694580078125\n",
      "Epoch: 23, iteration: 300\n",
      "Loss: 571.6597290039062\n",
      "Epoch: 23, iteration: 350\n",
      "Loss: 604.3007202148438\n",
      "Epoch: 23, iteration: 400\n",
      "Loss: 604.6137084960938\n",
      "Epoch: 23, iteration: 450\n",
      "Loss: 712.7868041992188\n",
      "Epoch: 23, iteration: 500\n",
      "Loss: 653.8543701171875\n",
      "Epoch: 23, iteration: 550\n",
      "Loss: 657.9146118164062\n",
      "Epoch: 23, iteration: 600\n",
      "Loss: 643.3606567382812\n",
      "Epoch: 23, iteration: 650\n",
      "Loss: 638.990966796875\n",
      "Epoch: 23, iteration: 700\n",
      "Loss: 723.7691040039062\n",
      "Epoch: 23, iteration: 750\n",
      "Loss: 715.96923828125\n",
      "Epoch: 23, iteration: 800\n",
      "Loss: 624.9447021484375\n",
      "Epoch: 23, iteration: 850\n",
      "Loss: 651.78076171875\n",
      "Epoch: 23, iteration: 900\n",
      "Loss: 605.2203369140625\n",
      "Epoch: 24, iteration: 0\n",
      "Loss: 622.56201171875\n",
      "Epoch: 24, iteration: 50\n",
      "Loss: 650.1986694335938\n",
      "Epoch: 24, iteration: 100\n",
      "Loss: 651.774169921875\n",
      "Epoch: 24, iteration: 150\n",
      "Loss: 626.4158935546875\n",
      "Epoch: 24, iteration: 200\n",
      "Loss: 660.7711181640625\n",
      "Epoch: 24, iteration: 250\n",
      "Loss: 566.5244750976562\n",
      "Epoch: 24, iteration: 300\n",
      "Loss: 586.7945556640625\n",
      "Epoch: 24, iteration: 350\n",
      "Loss: 645.897216796875\n",
      "Epoch: 24, iteration: 400\n",
      "Loss: 575.0284423828125\n",
      "Epoch: 24, iteration: 450\n",
      "Loss: 656.0011596679688\n",
      "Epoch: 24, iteration: 500\n",
      "Loss: 660.9429321289062\n",
      "Epoch: 24, iteration: 550\n",
      "Loss: 718.9356079101562\n",
      "Epoch: 24, iteration: 600\n",
      "Loss: 726.8687744140625\n",
      "Epoch: 24, iteration: 650\n",
      "Loss: 677.5013427734375\n",
      "Epoch: 24, iteration: 700\n",
      "Loss: 679.1929321289062\n",
      "Epoch: 24, iteration: 750\n",
      "Loss: 642.3731079101562\n",
      "Epoch: 24, iteration: 800\n",
      "Loss: 631.2978515625\n",
      "Epoch: 24, iteration: 850\n",
      "Loss: 707.8966674804688\n",
      "Epoch: 24, iteration: 900\n",
      "Loss: 493.5198059082031\n",
      "Epoch: 25, iteration: 0\n",
      "Loss: 553.2476196289062\n",
      "Epoch: 25, iteration: 50\n",
      "Loss: 675.5740356445312\n",
      "Epoch: 25, iteration: 100\n",
      "Loss: 645.779541015625\n",
      "Epoch: 25, iteration: 150\n",
      "Loss: 600.9744262695312\n",
      "Epoch: 25, iteration: 200\n",
      "Loss: 764.4554443359375\n",
      "Epoch: 25, iteration: 250\n",
      "Loss: 637.8417358398438\n",
      "Epoch: 25, iteration: 300\n",
      "Loss: 540.4335327148438\n",
      "Epoch: 25, iteration: 350\n",
      "Loss: 592.8646240234375\n",
      "Epoch: 25, iteration: 400\n",
      "Loss: 540.635986328125\n",
      "Epoch: 25, iteration: 450\n",
      "Loss: 723.43115234375\n",
      "Epoch: 25, iteration: 500\n",
      "Loss: 709.866455078125\n",
      "Epoch: 25, iteration: 550\n",
      "Loss: 730.9644165039062\n",
      "Epoch: 25, iteration: 600\n",
      "Loss: 650.3595581054688\n",
      "Epoch: 25, iteration: 650\n",
      "Loss: 655.6197509765625\n",
      "Epoch: 25, iteration: 700\n",
      "Loss: 639.7509765625\n",
      "Epoch: 25, iteration: 750\n",
      "Loss: 610.7913208007812\n",
      "Epoch: 25, iteration: 800\n",
      "Loss: 629.8345336914062\n",
      "Epoch: 25, iteration: 850\n",
      "Loss: 715.863037109375\n",
      "Epoch: 25, iteration: 900\n",
      "Loss: 496.28472900390625\n",
      "Epoch: 26, iteration: 0\n",
      "Loss: 590.334716796875\n",
      "Epoch: 26, iteration: 50\n",
      "Loss: 565.8894653320312\n",
      "Epoch: 26, iteration: 100\n",
      "Loss: 580.3357543945312\n",
      "Epoch: 26, iteration: 150\n",
      "Loss: 700.071533203125\n",
      "Epoch: 26, iteration: 200\n",
      "Loss: 743.5646362304688\n",
      "Epoch: 26, iteration: 250\n",
      "Loss: 711.5667114257812\n",
      "Epoch: 26, iteration: 300\n",
      "Loss: 524.7340698242188\n",
      "Epoch: 26, iteration: 350\n",
      "Loss: 579.262451171875\n",
      "Epoch: 26, iteration: 400\n",
      "Loss: 549.8413696289062\n",
      "Epoch: 26, iteration: 450\n",
      "Loss: 725.80517578125\n",
      "Epoch: 26, iteration: 500\n",
      "Loss: 645.9612426757812\n",
      "Epoch: 26, iteration: 550\n",
      "Loss: 766.0265502929688\n",
      "Epoch: 26, iteration: 600\n",
      "Loss: 524.8903198242188\n",
      "Epoch: 26, iteration: 650\n",
      "Loss: 613.6334228515625\n",
      "Epoch: 26, iteration: 700\n",
      "Loss: 596.2797241210938\n",
      "Epoch: 26, iteration: 750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 658.7423095703125\n",
      "Epoch: 26, iteration: 800\n",
      "Loss: 603.172607421875\n",
      "Epoch: 26, iteration: 850\n",
      "Loss: 625.0435791015625\n",
      "Epoch: 26, iteration: 900\n",
      "Loss: 528.85791015625\n",
      "Epoch: 27, iteration: 0\n",
      "Loss: 629.9856567382812\n",
      "Epoch: 27, iteration: 50\n",
      "Loss: 549.6632080078125\n",
      "Epoch: 27, iteration: 100\n",
      "Loss: 573.8804321289062\n",
      "Epoch: 27, iteration: 150\n",
      "Loss: 661.3981323242188\n",
      "Epoch: 27, iteration: 200\n",
      "Loss: 682.1069946289062\n",
      "Epoch: 27, iteration: 250\n",
      "Loss: 618.7634887695312\n",
      "Epoch: 27, iteration: 300\n",
      "Loss: 523.2164306640625\n",
      "Epoch: 27, iteration: 350\n",
      "Loss: 666.1204833984375\n",
      "Epoch: 27, iteration: 400\n",
      "Loss: 542.5817260742188\n",
      "Epoch: 27, iteration: 450\n",
      "Loss: 626.87255859375\n",
      "Epoch: 27, iteration: 500\n",
      "Loss: 547.4148559570312\n",
      "Epoch: 27, iteration: 550\n",
      "Loss: 746.9017333984375\n",
      "Epoch: 27, iteration: 600\n",
      "Loss: 555.3541870117188\n",
      "Epoch: 27, iteration: 650\n",
      "Loss: 584.998779296875\n",
      "Epoch: 27, iteration: 700\n",
      "Loss: 680.6825561523438\n",
      "Epoch: 27, iteration: 750\n",
      "Loss: 685.0950317382812\n",
      "Epoch: 27, iteration: 800\n",
      "Loss: 600.8401489257812\n",
      "Epoch: 27, iteration: 850\n",
      "Loss: 581.96875\n",
      "Epoch: 27, iteration: 900\n",
      "Loss: 537.4371948242188\n",
      "Epoch: 28, iteration: 0\n",
      "Loss: 648.3921508789062\n",
      "Epoch: 28, iteration: 50\n",
      "Loss: 632.1822509765625\n",
      "Epoch: 28, iteration: 100\n",
      "Loss: 679.9752197265625\n",
      "Epoch: 28, iteration: 150\n",
      "Loss: 574.1760864257812\n",
      "Epoch: 28, iteration: 200\n",
      "Loss: 747.10791015625\n",
      "Epoch: 28, iteration: 250\n",
      "Loss: 593.300537109375\n",
      "Epoch: 28, iteration: 300\n",
      "Loss: 626.951904296875\n",
      "Epoch: 28, iteration: 350\n",
      "Loss: 680.3190307617188\n",
      "Epoch: 28, iteration: 400\n",
      "Loss: 565.774169921875\n",
      "Epoch: 28, iteration: 450\n",
      "Loss: 617.3453979492188\n",
      "Epoch: 28, iteration: 500\n",
      "Loss: 595.7217407226562\n",
      "Epoch: 28, iteration: 550\n",
      "Loss: 719.4367065429688\n",
      "Epoch: 28, iteration: 600\n",
      "Loss: 631.08740234375\n",
      "Epoch: 28, iteration: 650\n",
      "Loss: 525.04833984375\n",
      "Epoch: 28, iteration: 700\n",
      "Loss: 736.197998046875\n",
      "Epoch: 28, iteration: 750\n",
      "Loss: 766.2672119140625\n",
      "Epoch: 28, iteration: 800\n",
      "Loss: 668.8502807617188\n",
      "Epoch: 28, iteration: 850\n",
      "Loss: 712.7245483398438\n",
      "Epoch: 28, iteration: 900\n",
      "Loss: 538.9010009765625\n",
      "Epoch: 29, iteration: 0\n",
      "Loss: 683.5028076171875\n",
      "Epoch: 29, iteration: 50\n",
      "Loss: 658.537841796875\n",
      "Epoch: 29, iteration: 100\n",
      "Loss: 813.119873046875\n",
      "Epoch: 29, iteration: 150\n",
      "Loss: 545.8323364257812\n",
      "Epoch: 29, iteration: 200\n",
      "Loss: 732.049560546875\n",
      "Epoch: 29, iteration: 250\n",
      "Loss: 624.215576171875\n",
      "Epoch: 29, iteration: 300\n",
      "Loss: 672.9750366210938\n",
      "Epoch: 29, iteration: 350\n",
      "Loss: 668.4666137695312\n",
      "Epoch: 29, iteration: 400\n",
      "Loss: 651.2166137695312\n",
      "Epoch: 29, iteration: 450\n",
      "Loss: 611.0445556640625\n",
      "Epoch: 29, iteration: 500\n",
      "Loss: 634.4674072265625\n",
      "Epoch: 29, iteration: 550\n",
      "Loss: 640.8856201171875\n",
      "Epoch: 29, iteration: 600\n",
      "Loss: 616.5379638671875\n",
      "Epoch: 29, iteration: 650\n",
      "Loss: 598.9345703125\n",
      "Epoch: 29, iteration: 700\n",
      "Loss: 610.0725708007812\n",
      "Epoch: 29, iteration: 750\n",
      "Loss: 764.0267333984375\n",
      "Epoch: 29, iteration: 800\n",
      "Loss: 686.6199951171875\n",
      "Epoch: 29, iteration: 850\n",
      "Loss: 729.53955078125\n",
      "Epoch: 29, iteration: 900\n",
      "Loss: 552.1011352539062\n",
      "Epoch: 30, iteration: 0\n",
      "Loss: 716.1107177734375\n",
      "Epoch: 30, iteration: 50\n",
      "Loss: 626.1975708007812\n",
      "Epoch: 30, iteration: 100\n",
      "Loss: 755.78759765625\n",
      "Epoch: 30, iteration: 150\n",
      "Loss: 545.8512573242188\n",
      "Epoch: 30, iteration: 200\n",
      "Loss: 733.0094604492188\n",
      "Epoch: 30, iteration: 250\n",
      "Loss: 663.8101196289062\n",
      "Epoch: 30, iteration: 300\n",
      "Loss: 605.5596923828125\n",
      "Epoch: 30, iteration: 350\n",
      "Loss: 594.54931640625\n",
      "Epoch: 30, iteration: 400\n",
      "Loss: 697.3856811523438\n",
      "Epoch: 30, iteration: 450\n",
      "Loss: 616.1900024414062\n",
      "Epoch: 30, iteration: 500\n",
      "Loss: 566.0738525390625\n",
      "Epoch: 30, iteration: 550\n",
      "Loss: 591.5750732421875\n",
      "Epoch: 30, iteration: 600\n",
      "Loss: 705.8536376953125\n",
      "Epoch: 30, iteration: 650\n",
      "Loss: 775.0921630859375\n",
      "Epoch: 30, iteration: 700\n",
      "Loss: 564.2537231445312\n",
      "Epoch: 30, iteration: 750\n",
      "Loss: 642.7479858398438\n",
      "Epoch: 30, iteration: 800\n",
      "Loss: 603.5843505859375\n",
      "Epoch: 30, iteration: 850\n",
      "Loss: 716.9940185546875\n",
      "Epoch: 30, iteration: 900\n",
      "Loss: 543.215576171875\n",
      "Epoch: 31, iteration: 0\n",
      "Loss: 670.10107421875\n",
      "Epoch: 31, iteration: 50\n",
      "Loss: 623.5167236328125\n",
      "Epoch: 31, iteration: 100\n",
      "Loss: 718.7203979492188\n",
      "Epoch: 31, iteration: 150\n",
      "Loss: 540.6593627929688\n",
      "Epoch: 31, iteration: 200\n",
      "Loss: 679.697998046875\n",
      "Epoch: 31, iteration: 250\n",
      "Loss: 641.8416137695312\n",
      "Epoch: 31, iteration: 300\n",
      "Loss: 661.5150146484375\n",
      "Epoch: 31, iteration: 350\n",
      "Loss: 691.3379516601562\n",
      "Epoch: 31, iteration: 400\n",
      "Loss: 638.9702758789062\n",
      "Epoch: 31, iteration: 450\n",
      "Loss: 647.6095581054688\n",
      "Epoch: 31, iteration: 500\n",
      "Loss: 554.382568359375\n",
      "Epoch: 31, iteration: 550\n",
      "Loss: 748.9705200195312\n",
      "Epoch: 31, iteration: 600\n",
      "Loss: 697.8601684570312\n",
      "Epoch: 31, iteration: 650\n",
      "Loss: 763.7724609375\n",
      "Epoch: 31, iteration: 700\n",
      "Loss: 590.0737915039062\n",
      "Epoch: 31, iteration: 750\n",
      "Loss: 630.242431640625\n",
      "Epoch: 31, iteration: 800\n",
      "Loss: 559.5694580078125\n",
      "Epoch: 31, iteration: 850\n",
      "Loss: 656.7274169921875\n",
      "Epoch: 31, iteration: 900\n",
      "Loss: 508.7443542480469\n",
      "Epoch: 32, iteration: 0\n",
      "Loss: 570.4146728515625\n",
      "Epoch: 32, iteration: 50\n",
      "Loss: 716.8997192382812\n",
      "Epoch: 32, iteration: 100\n",
      "Loss: 755.114501953125\n",
      "Epoch: 32, iteration: 150\n",
      "Loss: 575.5498046875\n",
      "Epoch: 32, iteration: 200\n",
      "Loss: 590.9682006835938\n",
      "Epoch: 32, iteration: 250\n",
      "Loss: 647.7133178710938\n",
      "Epoch: 32, iteration: 300\n",
      "Loss: 718.7677612304688\n",
      "Epoch: 32, iteration: 350\n",
      "Loss: 878.3984985351562\n",
      "Epoch: 32, iteration: 400\n",
      "Loss: 648.277587890625\n",
      "Epoch: 32, iteration: 450\n",
      "Loss: 614.1245727539062\n",
      "Epoch: 32, iteration: 500\n",
      "Loss: 615.417724609375\n",
      "Epoch: 32, iteration: 550\n",
      "Loss: 746.8793334960938\n",
      "Epoch: 32, iteration: 600\n",
      "Loss: 637.45263671875\n",
      "Epoch: 32, iteration: 650\n",
      "Loss: 597.703369140625\n",
      "Epoch: 32, iteration: 700\n",
      "Loss: 628.838623046875\n",
      "Epoch: 32, iteration: 750\n",
      "Loss: 641.9302368164062\n",
      "Epoch: 32, iteration: 800\n",
      "Loss: 662.2513427734375\n",
      "Epoch: 32, iteration: 850\n",
      "Loss: 653.0820922851562\n",
      "Epoch: 32, iteration: 900\n",
      "Loss: 455.37249755859375\n",
      "Epoch: 33, iteration: 0\n",
      "Loss: 562.9188232421875\n",
      "Epoch: 33, iteration: 50\n",
      "Loss: 690.7405395507812\n",
      "Epoch: 33, iteration: 100\n",
      "Loss: 696.5570678710938\n",
      "Epoch: 33, iteration: 150\n",
      "Loss: 564.1181640625\n",
      "Epoch: 33, iteration: 200\n",
      "Loss: 614.8809204101562\n",
      "Epoch: 33, iteration: 250\n",
      "Loss: 643.3155517578125\n",
      "Epoch: 33, iteration: 300\n",
      "Loss: 716.2069702148438\n",
      "Epoch: 33, iteration: 350\n",
      "Loss: 760.2310791015625\n",
      "Epoch: 33, iteration: 400\n",
      "Loss: 743.6825561523438\n",
      "Epoch: 33, iteration: 450\n",
      "Loss: 597.7891235351562\n",
      "Epoch: 33, iteration: 500\n",
      "Loss: 642.87255859375\n",
      "Epoch: 33, iteration: 550\n",
      "Loss: 695.7804565429688\n",
      "Epoch: 33, iteration: 600\n",
      "Loss: 733.108154296875\n",
      "Epoch: 33, iteration: 650\n",
      "Loss: 517.412353515625\n",
      "Epoch: 33, iteration: 700\n",
      "Loss: 603.8051147460938\n",
      "Epoch: 33, iteration: 750\n",
      "Loss: 604.3558959960938\n",
      "Epoch: 33, iteration: 800\n",
      "Loss: 713.94287109375\n",
      "Epoch: 33, iteration: 850\n",
      "Loss: 766.4085693359375\n",
      "Epoch: 33, iteration: 900\n",
      "Loss: 558.5010375976562\n",
      "Epoch: 34, iteration: 0\n",
      "Loss: 587.5440673828125\n",
      "Epoch: 34, iteration: 50\n",
      "Loss: 665.8291625976562\n",
      "Epoch: 34, iteration: 100\n",
      "Loss: 641.4762573242188\n",
      "Epoch: 34, iteration: 150\n",
      "Loss: 575.4841918945312\n",
      "Epoch: 34, iteration: 200\n",
      "Loss: 665.3739624023438\n",
      "Epoch: 34, iteration: 250\n",
      "Loss: 569.59912109375\n",
      "Epoch: 34, iteration: 300\n",
      "Loss: 730.9138793945312\n",
      "Epoch: 34, iteration: 350\n",
      "Loss: 662.9334106445312\n",
      "Epoch: 34, iteration: 400\n",
      "Loss: 825.29736328125\n",
      "Epoch: 34, iteration: 450\n",
      "Loss: 518.9239501953125\n",
      "Epoch: 34, iteration: 500\n",
      "Loss: 671.3164672851562\n",
      "Epoch: 34, iteration: 550\n",
      "Loss: 695.5556640625\n",
      "Epoch: 34, iteration: 600\n",
      "Loss: 796.8186645507812\n",
      "Epoch: 34, iteration: 650\n",
      "Loss: 568.4920654296875\n",
      "Epoch: 34, iteration: 700\n",
      "Loss: 569.8198852539062\n",
      "Epoch: 34, iteration: 750\n",
      "Loss: 583.4766235351562\n",
      "Epoch: 34, iteration: 800\n",
      "Loss: 633.2218017578125\n",
      "Epoch: 34, iteration: 850\n",
      "Loss: 785.0068359375\n",
      "Epoch: 34, iteration: 900\n",
      "Loss: 675.6467895507812\n",
      "Epoch: 35, iteration: 0\n",
      "Loss: 559.9310302734375\n",
      "Epoch: 35, iteration: 50\n",
      "Loss: 653.9156494140625\n",
      "Epoch: 35, iteration: 100\n",
      "Loss: 615.2450561523438\n",
      "Epoch: 35, iteration: 150\n",
      "Loss: 620.9374389648438\n",
      "Epoch: 35, iteration: 200\n",
      "Loss: 729.5497436523438\n",
      "Epoch: 35, iteration: 250\n",
      "Loss: 592.2271118164062\n",
      "Epoch: 35, iteration: 300\n",
      "Loss: 690.4920043945312\n",
      "Epoch: 35, iteration: 350\n",
      "Loss: 663.8697509765625\n",
      "Epoch: 35, iteration: 400\n",
      "Loss: 771.1781005859375\n",
      "Epoch: 35, iteration: 450\n",
      "Loss: 519.8771362304688\n",
      "Epoch: 35, iteration: 500\n",
      "Loss: 654.0611572265625\n",
      "Epoch: 35, iteration: 550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 661.8338012695312\n",
      "Epoch: 35, iteration: 600\n",
      "Loss: 744.7913818359375\n",
      "Epoch: 35, iteration: 650\n",
      "Loss: 625.2446899414062\n",
      "Epoch: 35, iteration: 700\n",
      "Loss: 574.5372924804688\n",
      "Epoch: 35, iteration: 750\n",
      "Loss: 624.4630126953125\n",
      "Epoch: 35, iteration: 800\n",
      "Loss: 617.948486328125\n",
      "Epoch: 35, iteration: 850\n",
      "Loss: 797.1436767578125\n",
      "Epoch: 35, iteration: 900\n",
      "Loss: 704.3880615234375\n",
      "Epoch: 36, iteration: 0\n",
      "Loss: 643.9791259765625\n",
      "Epoch: 36, iteration: 50\n",
      "Loss: 669.25\n",
      "Epoch: 36, iteration: 100\n",
      "Loss: 714.7491455078125\n",
      "Epoch: 36, iteration: 150\n",
      "Loss: 609.5266723632812\n",
      "Epoch: 36, iteration: 200\n",
      "Loss: 804.801513671875\n",
      "Epoch: 36, iteration: 250\n",
      "Loss: 666.3084106445312\n",
      "Epoch: 36, iteration: 300\n",
      "Loss: 685.04736328125\n",
      "Epoch: 36, iteration: 350\n",
      "Loss: 675.7203979492188\n",
      "Epoch: 36, iteration: 400\n",
      "Loss: 654.051513671875\n",
      "Epoch: 36, iteration: 450\n",
      "Loss: 618.3573608398438\n",
      "Epoch: 36, iteration: 500\n",
      "Loss: 589.2176513671875\n",
      "Epoch: 36, iteration: 550\n",
      "Loss: 719.7635498046875\n",
      "Epoch: 36, iteration: 600\n",
      "Loss: 719.9124145507812\n",
      "Epoch: 36, iteration: 650\n",
      "Loss: 554.6259765625\n",
      "Epoch: 36, iteration: 700\n",
      "Loss: 756.1903686523438\n",
      "Epoch: 36, iteration: 750\n",
      "Loss: 650.1848754882812\n",
      "Epoch: 36, iteration: 800\n",
      "Loss: 612.7680053710938\n",
      "Epoch: 36, iteration: 850\n",
      "Loss: 868.3518676757812\n",
      "Epoch: 36, iteration: 900\n",
      "Loss: 776.7723388671875\n",
      "Epoch: 37, iteration: 0\n",
      "Loss: 728.8270263671875\n",
      "Epoch: 37, iteration: 50\n",
      "Loss: 691.8906860351562\n",
      "Epoch: 37, iteration: 100\n",
      "Loss: 675.8947143554688\n",
      "Epoch: 37, iteration: 150\n",
      "Loss: 643.5642700195312\n",
      "Epoch: 37, iteration: 200\n",
      "Loss: 977.1421508789062\n",
      "Epoch: 37, iteration: 250\n",
      "Loss: 639.3184204101562\n",
      "Epoch: 37, iteration: 300\n",
      "Loss: 675.4003295898438\n",
      "Epoch: 37, iteration: 350\n",
      "Loss: 746.3475952148438\n",
      "Epoch: 37, iteration: 400\n",
      "Loss: 643.0172119140625\n",
      "Epoch: 37, iteration: 450\n",
      "Loss: 638.3677368164062\n",
      "Epoch: 37, iteration: 500\n",
      "Loss: 565.747314453125\n",
      "Epoch: 37, iteration: 550\n",
      "Loss: 670.1389770507812\n",
      "Epoch: 37, iteration: 600\n",
      "Loss: 758.2101440429688\n",
      "Epoch: 37, iteration: 650\n",
      "Loss: 599.8016357421875\n",
      "Epoch: 37, iteration: 700\n",
      "Loss: 816.9528198242188\n",
      "Epoch: 37, iteration: 750\n",
      "Loss: 618.297119140625\n",
      "Epoch: 37, iteration: 800\n",
      "Loss: 615.3034057617188\n",
      "Epoch: 37, iteration: 850\n",
      "Loss: 659.1202392578125\n",
      "Epoch: 37, iteration: 900\n",
      "Loss: 740.3226928710938\n",
      "Epoch: 38, iteration: 0\n",
      "Loss: 677.9109497070312\n",
      "Epoch: 38, iteration: 50\n",
      "Loss: 624.2869873046875\n",
      "Epoch: 38, iteration: 100\n",
      "Loss: 564.7117919921875\n",
      "Epoch: 38, iteration: 150\n",
      "Loss: 630.43896484375\n",
      "Epoch: 38, iteration: 200\n",
      "Loss: 1124.576171875\n",
      "Epoch: 38, iteration: 250\n",
      "Loss: 585.1831665039062\n",
      "Epoch: 38, iteration: 300\n",
      "Loss: 710.2570190429688\n",
      "Epoch: 38, iteration: 350\n",
      "Loss: 683.0499267578125\n",
      "Epoch: 38, iteration: 400\n",
      "Loss: 619.2090454101562\n",
      "Epoch: 38, iteration: 450\n",
      "Loss: 596.7941284179688\n",
      "Epoch: 38, iteration: 500\n",
      "Loss: 489.2789306640625\n",
      "Epoch: 38, iteration: 550\n",
      "Loss: 624.6029052734375\n",
      "Epoch: 38, iteration: 600\n",
      "Loss: 789.0572509765625\n",
      "Epoch: 38, iteration: 650\n",
      "Loss: 678.0806884765625\n",
      "Epoch: 38, iteration: 700\n",
      "Loss: 618.8648071289062\n",
      "Epoch: 38, iteration: 750\n",
      "Loss: 565.1197509765625\n",
      "Epoch: 38, iteration: 800\n",
      "Loss: 570.2855224609375\n",
      "Epoch: 38, iteration: 850\n",
      "Loss: 487.11175537109375\n",
      "Epoch: 38, iteration: 900\n",
      "Loss: 591.4529418945312\n",
      "Epoch: 39, iteration: 0\n",
      "Loss: 555.6141357421875\n",
      "Epoch: 39, iteration: 50\n",
      "Loss: 686.1868896484375\n",
      "Epoch: 39, iteration: 100\n",
      "Loss: 583.0986328125\n",
      "Epoch: 39, iteration: 150\n",
      "Loss: 607.2523193359375\n",
      "Epoch: 39, iteration: 200\n",
      "Loss: 1158.9327392578125\n",
      "Epoch: 39, iteration: 250\n",
      "Loss: 632.940185546875\n",
      "Epoch: 39, iteration: 300\n",
      "Loss: 649.74951171875\n",
      "Epoch: 39, iteration: 350\n",
      "Loss: 607.5796508789062\n",
      "Epoch: 39, iteration: 400\n",
      "Loss: 579.697509765625\n",
      "Epoch: 39, iteration: 450\n",
      "Loss: 527.9654541015625\n",
      "Epoch: 39, iteration: 500\n",
      "Loss: 499.24530029296875\n",
      "Epoch: 39, iteration: 550\n",
      "Loss: 626.9700927734375\n",
      "Epoch: 39, iteration: 600\n",
      "Loss: 730.10888671875\n",
      "Epoch: 39, iteration: 650\n",
      "Loss: 614.7054443359375\n",
      "Epoch: 39, iteration: 700\n",
      "Loss: 577.06787109375\n",
      "Epoch: 39, iteration: 750\n",
      "Loss: 559.6864624023438\n",
      "Epoch: 39, iteration: 800\n",
      "Loss: 558.8408813476562\n",
      "Epoch: 39, iteration: 850\n",
      "Loss: 544.6141357421875\n",
      "Epoch: 39, iteration: 900\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train(train_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-18T11:07:52.484814Z",
     "start_time": "2018-12-18T11:07:52.482236Z"
    }
   },
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
